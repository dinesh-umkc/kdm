{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBFHasqZ1u7jR6PK3DvLX+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinesh-umkc/kdm/blob/main/ICP6_LCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LCA- Topic Modeling\n",
        "#Objective\n",
        "1. Get books from https://www.gutenberg.org \n",
        "2. Clean content from book data\n",
        "3. Get topics using LCA\n",
        "4. Get content from these threads\n",
        " - 2meirl4meirl — 842,000 subscribers\n",
        " - disneyvacation — 478,000 subscribers\n",
        " - unresolvedmysteries — 732,000 subscribers\n",
        " - wewantplates — 502,000 subscribers\n",
        " - antiMLM — 493,000 subscribers\n",
        "5. Clean content from thread data\n",
        "6. Get topics using LCA"
      ],
      "metadata": {
        "id": "exDdnjbDA0Sp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oMCoc3J-AW_q"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "documents = []\n",
        "\n",
        "import re\n",
        "regex = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_html(string):\n",
        "    return regex.sub('', string)\n",
        "\n",
        "def getContent(url): \n",
        "  #url = \"https://www.gutenberg.org/files/55/55-h/55-h.htm\" \n",
        "  html = urlopen(url).read()\n",
        "  soup = BeautifulSoup(html, features=\"html.parser\")\n",
        "  for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()\n",
        "  text = soup.get_text()\n",
        "  documents.append(remove_html(text))\n",
        "\n",
        "url=\"https://www.gutenberg.org/files/55/55-h/55-h.htm\"\n",
        "getContent(url)\n",
        "(documents[0])[:500]\n",
        "url = \"https://www.gutenberg.org/files/54/54-h/54-h.htm\" \n",
        "getContent(url)\n",
        "url = \"https://www.gutenberg.org/files/33361/33361-h/33361-h.htm\" \n",
        "getContent(url)\n",
        "url = \"https://www.gutenberg.org/files/22566/22566-h/22566-h.htm\" \n",
        "getContent(url)\n",
        "url = \"https://www.gutenberg.org/files/26624/26624-h/26624-h.htm\" \n",
        "getContent(url)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "\n",
        "tfidf_vect = CountVectorizer(analyzer='word', stop_words = 'english')\n",
        "df=tfidf_vect.fit_transform(documents)\n",
        "vocab = tfidf_vect.get_feature_names_out()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMw2_-yuL7M-",
        "outputId": "cc4d8560-7638-4b41-e7a8-3ae7daa28ac4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDR4ZUcXNDu_",
        "outputId": "e36a8ac3-3f1c-469c-a8de-d071b1a0ed20"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['00', '000', '10', ..., 'zoroaster', 'zuz', 'zy'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNC1YuqKNIfa",
        "outputId": "b709690e-6022-49fe-8ac3-0a8dcecd48a7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 8851)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1srVjFLOj7k",
        "outputId": "2a8e6c48-e6d8-426f-d07f-837751267319"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 5177)\t0.0010695255139764681\n",
            "  (0, 7601)\t0.0010695255139764681\n",
            "  (0, 5952)\t0.0010695255139764681\n",
            "  (0, 2958)\t0.0010695255139764681\n",
            "  (0, 5626)\t0.0010695255139764681\n",
            "  (0, 4749)\t0.0010695255139764681\n",
            "  (0, 2655)\t0.0010695255139764681\n",
            "  (0, 5136)\t0.0010695255139764681\n",
            "  (0, 1783)\t0.0010695255139764681\n",
            "  (0, 8434)\t0.0010695255139764681\n",
            "  (0, 5168)\t0.0010695255139764681\n",
            "  (0, 4675)\t0.0010695255139764681\n",
            "  (0, 5953)\t0.0010695255139764681\n",
            "  (0, 6889)\t0.0010695255139764681\n",
            "  (0, 5361)\t0.0010695255139764681\n",
            "  (0, 3775)\t0.0010695255139764681\n",
            "  (0, 4913)\t0.0010695255139764681\n",
            "  (0, 5957)\t0.0010695255139764681\n",
            "  (0, 1352)\t0.0010695255139764681\n",
            "  (0, 2005)\t0.0010695255139764681\n",
            "  (0, 8527)\t0.0010695255139764681\n",
            "  (0, 401)\t0.0010695255139764681\n",
            "  (0, 4910)\t0.0010695255139764681\n",
            "  (0, 2484)\t0.0010695255139764681\n",
            "  (0, 5427)\t0.0010695255139764681\n",
            "  :\t:\n",
            "  (0, 4644)\t0.007486678597835278\n",
            "  (0, 5353)\t0.010695255139764681\n",
            "  (0, 8794)\t0.010695255139764681\n",
            "  (0, 5320)\t0.004278102055905873\n",
            "  (0, 4108)\t0.003208576541929405\n",
            "  (0, 4567)\t0.01925145925157643\n",
            "  (0, 7827)\t0.0235295613074823\n",
            "  (0, 766)\t0.07593631149232924\n",
            "  (0, 1886)\t0.01283430616771762\n",
            "  (0, 8573)\t0.0021390510279529363\n",
            "  (0, 6420)\t0.0021390510279529363\n",
            "  (0, 1915)\t0.004278102055905873\n",
            "  (0, 8749)\t0.020320984765552896\n",
            "  (0, 5481)\t0.002529046141431025\n",
            "  (0, 7421)\t0.020320984765552896\n",
            "  (0, 8255)\t0.016042882709647023\n",
            "  (0, 8323)\t0.02994671439134111\n",
            "  (0, 860)\t0.005347627569882341\n",
            "  (0, 3303)\t0.005347627569882341\n",
            "  (0, 5411)\t0.18074981186202313\n",
            "  (0, 8697)\t0.0470591226149646\n",
            "  (0, 8716)\t0.02994671439134111\n",
            "  (0, 2645)\t0.014973357195670556\n",
            "  (0, 3695)\t0.10588302588367035\n",
            "  (0, 5966)\t0.09518777074390568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (vocab[5177])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAwmUK6-OsYI",
        "outputId": "d147ba31-de47-4501-f953-00b09629270e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "newsletter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda = LatentDirichletAllocation(n_components = 5, doc_topic_prior=1)\n",
        "lda.fit(df)\n",
        "lda.components_[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhgzFjoaO46U",
        "outputId": "5b464431-ef6e-4279-d0e4-72f4cc38afb8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8851,)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "topic_words = {}\n",
        "n_top_words = 20\n",
        "for topic, comp in enumerate(lda.components_):\n",
        "    # print(topic, comp)\n",
        "    word_idx = np.argsort(comp)[::-1][:n_top_words] #argsort to get index, and [::-1] to sort in descending\n",
        "    # store the words most relevant to the topic\n",
        "    topic_words[topic] = [vocab[i] for i in word_idx]\n",
        "    # break\n",
        "    \n",
        "for topic, words in topic_words.items():\n",
        "    print('Topic: %d' % topic)\n",
        "    print('  %s' % ', '.join(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwnVMf5yPBaq",
        "outputId": "10b9604c-176b-40b3-c6b6-3574096e9b97"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0\n",
            "  dorothy, said, scarecrow, woodman, lion, oz, great, tin, little, witch, asked, green, came, good, gutenberg, girl, toto, head, project, shall\n",
            "Topic: 1\n",
            "  said, tip, scarecrow, horse, jack, saw, woodman, tin, pumpkinhead, mombi, city, boy, woggle, bug, head, gutenberg, glinda, good, old, project\n",
            "Topic: 2\n",
            "  actual, shown, tinkling, accepting, spoil, boards, furniture, towers, stern, missing, errors, assorted, putting, throwing, preserve, dull, strict, heartily, secure, main\n",
            "Topic: 3\n",
            "  dorothy, said, man, little, wizard, shaggy, pg, asked, bright, gutenberg, ozma, button, project, oz, like, don, time, good, jim, people\n",
            "Topic: 4\n",
            "  dorothy, said, pg, king, billina, ozma, hen, scarecrow, girl, nome, little, tiktok, ev, tin, oz, gutenberg, palace, project, asked, woodman\n"
          ]
        }
      ]
    }
  ]
}