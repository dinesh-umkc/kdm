{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinesh-umkc/kdm/blob/main/Language_Detection_(with_Stop_Words)_ICP1_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95ymCegLxqyt"
      },
      "source": [
        "# Detecting Text Language by Counting Stop Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45aVQXCKxqyw"
      },
      "source": [
        "*Stop words* are words which are filtered out before processing because they are mostly grammatical as opposed to semantic in nature e.g. search engines remove words/phrases like 'I want'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPxCvCUvxqyx"
      },
      "source": [
        "## 1. Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rNEk-kWxqyy",
        "outputId": "62b6c0f7-44f3-4651-f4e0-1fe3cf28cd7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'oito', 'chama', 'e', 'quando', 'anos', 'mãe', 'luciano', 'possui', 'gosta', 'está', 'férias', 'olívia', 'seus', '-', 'novelas', 'tem', 'uma', 'que', 'castanhos', 'de', 'sua', 'cultivar', 'jardim', 'familiares', 'família', 'um', 'se', 'assistir', 'muito', '.', 'rosas', 'ela', 'desenhar', 'ele', 'admira', 'longos', 'cabelos', 'brancas'}\n",
            "portuguese\n",
            "{'methoden', 'einst', 'eine', 'vorhandener', 'fähigkeiten', 'zuhause', 'oder', 'umfeld', '-', 'mit', 'durchdachten', 'ist', 'lernen', 'vertiefung', 'lingua', 'in', 'zum', 'neuer', '!', 'sprachen', 'einem', ',', 'neue', 'unterwegs', 'möglichkeit', 'bestehender', 'das', 'technik', 'und', '.', 'modernster', 'zur', 'zielgerichtetes', 'erfrischende', 'motivierenden', 'training'}\n",
            "german\n",
            "{'orientado', 'aprende', 'conocimientos', 'recupera', 'a', 'en', 'tecnología', 'un', 'con', 'o', 'habilidades', 'permitirá', 'entrenamiento', 'aprender', 'mediante', 'donde', 'cero', 'que', 'allá', 'y', 'motivador', 'tus', 'la', ',', 'método', 'ya', 'estés', 'pedagógico', 'gracias', 'adquiridas', 'entorno', '.', 'desde', 'te', 'amplía', 'idioma', 'nuevo', 'objetivos'}\n",
            "spanish\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "def detectLanguage(input):\n",
        "    language_ratios = {}\n",
        "    test_tokens = wordpunct_tokenize(input)\n",
        "    test_words = [word.lower() for word in test_tokens] # lowercase all tokens\n",
        "    test_words_set = set(test_words)\n",
        "    print(test_words_set)\n",
        "    for language in stopwords.fileids():\n",
        "        stopwords_set = set(stopwords.words(language)) # For some languages eg. Russian, it would be a wise idea to tokenize the stop words by punctuation too.\n",
        "        common_elements = test_words_set.intersection(stopwords_set)\n",
        "        language_ratios[language] = len(common_elements) # language \"score\" by counting\n",
        "    language_ratios    \n",
        "    most_rated_language = max(language_ratios, key=language_ratios.get)\n",
        "    return most_rated_language\n",
        "text1 = \"Luciano tem oito anos e possui uma família que admira muito. Ele gosta de desenhar seus familiares quando está de férias.Sua mãe chama-se Olívia e tem cabelos castanhos e longos. Ela gosta de assistir novelas e cultivar um jardim de rosas brancas.\"\n",
        "print(detectLanguage(text1))\n",
        "text1 = \"Eine neue und erfrischende Möglichkeit zum Lernen neuer Sprachen und zur Vertiefung bestehender oder einst vorhandener Fähigkeiten. Zielgerichtetes Training mit durchdachten Methoden, in einem motivierenden Umfeld, mit modernster Technik, zuhause und unterwegs - das ist Lingua!\"\n",
        "print(detectLanguage(text1))\n",
        "text1=\"Aprende un idioma nuevo desde cero, amplía tus conocimientos o recupera habilidades ya adquiridas, mediante un entrenamiento orientado a objetivos, en un entorno motivador y con un método pedagógico que, gracias a la tecnología, te permitirá aprender allá donde estés.\"\n",
        "print(detectLanguage(text1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ICP: Perform language detection on a corpus/custom text. \n",
        "\n",
        "1.   Choose your own sentence/paragraph and perform language classification above by \n",
        "loading a longer `.txt` file or a random sentence from a corpus from NLTK.\n",
        "2.   Detect 3 languages from one or more corpora\n",
        "\n",
        "\n",
        "\n",
        "Hint (if you are using NLTK):\n",
        "\n",
        "```python\n",
        "import nltk.corpus\n",
        "from nltk.corpus import genesis\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "_tklDciCBR5J"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Language Detection (with Stop Words)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}