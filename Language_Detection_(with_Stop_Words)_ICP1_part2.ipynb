{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinesh-umkc/kdm/blob/main/Language_Detection_(with_Stop_Words)_ICP1_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95ymCegLxqyt"
      },
      "source": [
        "# Detecting Text Language by Counting Stop Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45aVQXCKxqyw"
      },
      "source": [
        "#Objective\n",
        "Detect at least threelanguage by counting stop words\n",
        "1. Tried to use NLTK corpus, however could not figure out how, added three random texts from three diffent language and this program could detect it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPxCvCUvxqyx"
      },
      "source": [
        "## 1. Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rNEk-kWxqyy",
        "outputId": "62b6c0f7-44f3-4651-f4e0-1fe3cf28cd7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'oito', 'chama', 'e', 'quando', 'anos', 'mãe', 'luciano', 'possui', 'gosta', 'está', 'férias', 'olívia', 'seus', '-', 'novelas', 'tem', 'uma', 'que', 'castanhos', 'de', 'sua', 'cultivar', 'jardim', 'familiares', 'família', 'um', 'se', 'assistir', 'muito', '.', 'rosas', 'ela', 'desenhar', 'ele', 'admira', 'longos', 'cabelos', 'brancas'}\n",
            "portuguese\n",
            "{'methoden', 'einst', 'eine', 'vorhandener', 'fähigkeiten', 'zuhause', 'oder', 'umfeld', '-', 'mit', 'durchdachten', 'ist', 'lernen', 'vertiefung', 'lingua', 'in', 'zum', 'neuer', '!', 'sprachen', 'einem', ',', 'neue', 'unterwegs', 'möglichkeit', 'bestehender', 'das', 'technik', 'und', '.', 'modernster', 'zur', 'zielgerichtetes', 'erfrischende', 'motivierenden', 'training'}\n",
            "german\n",
            "{'orientado', 'aprende', 'conocimientos', 'recupera', 'a', 'en', 'tecnología', 'un', 'con', 'o', 'habilidades', 'permitirá', 'entrenamiento', 'aprender', 'mediante', 'donde', 'cero', 'que', 'allá', 'y', 'motivador', 'tus', 'la', ',', 'método', 'ya', 'estés', 'pedagógico', 'gracias', 'adquiridas', 'entorno', '.', 'desde', 'te', 'amplía', 'idioma', 'nuevo', 'objetivos'}\n",
            "spanish\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "def detectLanguage(input):\n",
        "    language_ratios = {}\n",
        "    test_tokens = wordpunct_tokenize(input)\n",
        "    test_words = [word.lower() for word in test_tokens] # lowercase all tokens\n",
        "    test_words_set = set(test_words)\n",
        "    print(test_words_set)\n",
        "    for language in stopwords.fileids():\n",
        "        stopwords_set = set(stopwords.words(language)) # For some languages eg. Russian, it would be a wise idea to tokenize the stop words by punctuation too.\n",
        "        common_elements = test_words_set.intersection(stopwords_set)\n",
        "        language_ratios[language] = len(common_elements) # language \"score\" by counting\n",
        "    language_ratios    \n",
        "    most_rated_language = max(language_ratios, key=language_ratios.get)\n",
        "    return most_rated_language\n",
        "text1 = \"Luciano tem oito anos e possui uma família que admira muito. Ele gosta de desenhar seus familiares quando está de férias.Sua mãe chama-se Olívia e tem cabelos castanhos e longos. Ela gosta de assistir novelas e cultivar um jardim de rosas brancas.\"\n",
        "print(detectLanguage(text1))\n",
        "text1 = \"Eine neue und erfrischende Möglichkeit zum Lernen neuer Sprachen und zur Vertiefung bestehender oder einst vorhandener Fähigkeiten. Zielgerichtetes Training mit durchdachten Methoden, in einem motivierenden Umfeld, mit modernster Technik, zuhause und unterwegs - das ist Lingua!\"\n",
        "print(detectLanguage(text1))\n",
        "text1=\"Aprende un idioma nuevo desde cero, amplía tus conocimientos o recupera habilidades ya adquiridas, mediante un entrenamiento orientado a objetivos, en un entorno motivador y con un método pedagógico que, gracias a la tecnología, te permitirá aprender allá donde estés.\"\n",
        "print(detectLanguage(text1))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Language Detection (with Stop Words)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}