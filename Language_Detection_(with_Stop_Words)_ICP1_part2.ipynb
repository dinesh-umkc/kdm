{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinesh-umkc/kdm/blob/main/Language_Detection_(with_Stop_Words)_ICP1_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95ymCegLxqyt"
      },
      "source": [
        "# Detecting Text Language by Counting Stop Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45aVQXCKxqyw"
      },
      "source": [
        "*Stop words* are words which are filtered out before processing because they are mostly grammatical as opposed to semantic in nature e.g. search engines remove words/phrases like 'I want'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPxCvCUvxqyx"
      },
      "source": [
        "## 1. Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rNEk-kWxqyy",
        "outputId": "48de7f03-58c3-4bda-f355-c1f0060d49be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/webtext.zip.\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/genesis.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('webtext')\n",
        "nltk.download('reuters')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "nltk.download('genesis')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Dieu les bénit , et Dieu leur dit : Soyez féconds , multipliez , remplissez la terre , et l ' assujettissez ; et dominez sur les poissons de la mer ,\"\n",
        "# text = \"I can do this all day. I love you 3000.\"\n",
        "\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4jv9rzu6yOz",
        "outputId": "f4282b7d-bd54-41c9-f310-7aed162f2368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dieu les bénit , et Dieu leur dit : Soyez féconds , multipliez , remplissez la terre , et l ' assujettissez ; et dominez sur les poissons de la mer ,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genesis.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuqgTbQMAoDM",
        "outputId": "26500c54-87fd-4f5f-e6ce-4c0823b397a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['english-kjv.txt',\n",
              " 'english-web.txt',\n",
              " 'finnish.txt',\n",
              " 'french.txt',\n",
              " 'german.txt',\n",
              " 'lolcat.txt',\n",
              " 'portuguese.txt',\n",
              " 'swedish.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhQJ3HcIxqyz",
        "outputId": "2120ee87-3983-41fe-d89a-0bf02e06b434"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dieu',\n",
              " 'les',\n",
              " 'bénit',\n",
              " ',',\n",
              " 'et',\n",
              " 'Dieu',\n",
              " 'leur',\n",
              " 'dit',\n",
              " ':',\n",
              " 'Soyez',\n",
              " 'féconds',\n",
              " ',',\n",
              " 'multipliez',\n",
              " ',',\n",
              " 'remplissez',\n",
              " 'la',\n",
              " 'terre',\n",
              " ',',\n",
              " 'et',\n",
              " 'l',\n",
              " \"'\",\n",
              " 'assujettissez',\n",
              " ';',\n",
              " 'et',\n",
              " 'dominez',\n",
              " 'sur',\n",
              " 'les',\n",
              " 'poissons',\n",
              " 'de',\n",
              " 'la',\n",
              " 'mer',\n",
              " ',']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "test_tokens = wordpunct_tokenize(text)\n",
        "test_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrAlIuqBxqy0"
      },
      "source": [
        "There are other tokenizers e.g. `RegexpTokenizer` where you can enter your own regexp, `WhitespaceTokenizer` (similar to Python's `string.split()`) and `BlanklineTokenizer`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deZWn89jxqy0"
      },
      "source": [
        "## 2. Exploring NLTK's stop words corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgXWNdhKxqy1"
      },
      "source": [
        "NLTK comes with a corpus of stop words in various languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8FNkNZ4xqy1",
        "outputId": "2c1e8bc7-a9f9-4257-9f7d-f7163722e87a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopwords Corpus\n",
            "\n",
            "This corpus contains lists of stop words for several languages.  These\n",
            "are high-frequency grammatical words which are usually ignored in text\n",
            "retrieval applications.\n",
            "\n",
            "They were obtained from:\n",
            "http://anoncvs.postgresql.org/cvsweb.cgi/pgsql/src/backend/snowball/stopwords/\n",
            "\n",
            "The stop words for the Romanian language were obtained from:\n",
            "http://arlc.ro/resources/\n",
            "\n",
            "The English list has been augmented\n",
            "https://github.com/nltk/nltk_data/issues/22\n",
            "\n",
            "The German list has been corrected\n",
            "https://github.com/nltk/nltk_data/pull/49\n",
            "\n",
            "A Kazakh list has been added\n",
            "https://github.com/nltk/nltk_data/pull/52\n",
            "\n",
            "A Nepali list has been added\n",
            "https://github.com/nltk/nltk_data/pull/83\n",
            "\n",
            "An Azerbaijani list has been added\n",
            "https://github.com/nltk/nltk_data/pull/100\n",
            "\n",
            "A Greek list has been added\n",
            "https://github.com/nltk/nltk_data/pull/103\n",
            "\n",
            "An Indonesian list has been added\n",
            "https://github.com/nltk/nltk_data/pull/112\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "print(stopwords.readme())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XMhfEexxqy2",
        "outputId": "e81a244c-0358-4afa-fb28-87fca86cc0c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['arabic',\n",
              " 'azerbaijani',\n",
              " 'basque',\n",
              " 'bengali',\n",
              " 'catalan',\n",
              " 'chinese',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'greek',\n",
              " 'hebrew',\n",
              " 'hinglish',\n",
              " 'hungarian',\n",
              " 'indonesian',\n",
              " 'italian',\n",
              " 'kazakh',\n",
              " 'nepali',\n",
              " 'norwegian',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'slovene',\n",
              " 'spanish',\n",
              " 'swedish',\n",
              " 'tajik',\n",
              " 'turkish']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "stopwords.fileids() # Most corpora consist of a set of files, each containing a piece of text. A list of identifiers for these files is accessed via fileids()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eAIDqjJxqy2"
      },
      "source": [
        "Corpus readers provide a variety of methods to read data from the corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "Ih71vRf5xqy3",
        "outputId": "201e3034-1cb1-4b2b-903a-98e8a07f477f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"αλλα\\nαν\\nαντι\\nαπο\\nαυτα\\nαυτεσ\\nαυτη\\nαυτο\\nαυτοι\\nαυτοσ\\nαυτουσ\\nαυτων\\nαἱ\\nαἳ\\nαἵ\\nαὐτόσ\\nαὐτὸς\\nαὖ\\nγάρ\\nγα\\nγα^\\nγε\\nγια\\nγοῦν\\nγὰρ\\nδ'\\nδέ\\nδή\\nδαί\\nδαίσ\\nδαὶ\\nδαὶς\\nδε\\nδεν\\nδι'\\nδιά\\nδιὰ\\nδὲ\\nδὴ\\nδ’\\nεαν\\nειμαι\\nειμαστε\\nειναι\\nεισαι\\nειστε\\nεκεινα\\nεκεινεσ\\nεκεινη\\nεκεινο\\nεκεινοι\\nεκεινοσ\\nεκεινουσ\\nεκεινων\\nενω\\nεπ\\nεπι\\nεἰ\\nεἰμί\\nεἰμὶ\\nεἰς\\nεἰσ\\nεἴ\\nεἴμι\\nεἴτε\\nη\\nθα\\nισωσ\\nκ\\nκαί\\nκαίτοι\\nκαθ\\nκαι\\nκατ\\nκατά\\nκατα\\nκατὰ\\nκαὶ\\nκι\\nκἀν\\nκἂν\\nμέν\\nμή\\nμήτε\\nμα\\nμε\\nμεθ\\nμετ\\nμετά\\nμετα\\nμετὰ\\nμη\\nμην\\nμἐν\\nμὲν\\nμὴ\\nμὴν\\nνα\\nο\\nοι\\nομωσ\\nοπωσ\\nοσο\\nοτι\\nοἱ\\nοἳ\\nοἷς\\nοὐ\\nοὐδ\\nοὐδέ\\nοὐδείσ\\nοὐδεὶς\\nοὐδὲ\\nοὐδὲν\\nοὐκ\\nοὐχ\\nοὐχὶ\\nοὓς\\nοὔτε\\nοὕτω\\nοὕτως\\nοὕτωσ\\nοὖν\\nοὗ\\nοὗτος\\nοὗτοσ\\nπαρ\\nπαρά\\nπαρα\\nπαρὰ\\nπερί\\nπερὶ\\nποια\\nποιεσ\\nποιο\\nποιοι\\nποιοσ\\nποιουσ\\nποιων\\nποτε\\nπου\\nποῦ\\nπρο\\nπροσ\\nπρόσ\\nπρὸ\\nπρὸς\\nπως\\nπωσ\\nσε\\nστη\\nστην\\nστο\\nστον\\nσόσ\\nσύ\\nσύν\\nσὸς\\nσὺ\\nσὺν\\nτά\\nτήν\\nτί\\nτίς\\nτίσ\\nτα\\nταῖς\\nτε\\nτην\\nτησ\\nτι\\nτινα\\nτις\\nτισ\\nτο\\nτοί\\nτοι\\nτοιοῦτος\\nτοιοῦτοσ\\nτον\\nτοτε\\nτου\\nτούσ\\nτοὺς\\nτοῖς\\nτοῦ\\nτων\\nτό\\nτόν\\nτότε\\nτὰ\\nτὰς\\nτὴν\\nτὸ\\nτὸν\\nτῆς\\nτῆσ\\nτῇ\\nτῶν\\nτῷ\\nωσ\\nἀλλ'\\nἀλλά\\nἀλλὰ\\nἀλλ’\\nἀπ\\nἀπό\\nἀπὸ\\nἀφ\\nἂν\\nἃ\\nἄλλος\\nἄλλοσ\\nἄν\\nἄρα\\nἅμα\\nἐάν\\nἐγώ\\nἐγὼ\\nἐκ\\nἐμόσ\\nἐμὸς\\nἐν\\nἐξ\\nἐπί\\nἐπεὶ\\nἐπὶ\\nἐστι\\nἐφ\\nἐὰν\\nἑαυτοῦ\\nἔτι\\nἡ\\nἢ\\nἣ\\nἤ\\nἥ\\nἧς\\nἵνα\\nὁ\\nὃ\\nὃν\\nὃς\\nὅ\\nὅδε\\nὅθεν\\nὅπερ\\nὅς\\nὅσ\\nὅστις\\nὅστισ\\nὅτε\\nὅτι\\nὑμόσ\\nὑπ\\nὑπέρ\\nὑπό\\nὑπὲρ\\nὑπὸ\\nὡς\\nὡσ\\nὥς\\nὥστε\\nὦ\\nᾧ\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "stopwords.raw('greek')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "XwBmhMJjxqy3",
        "outputId": "df3b6dc8-1a94-4bc4-91ce-01e6897e3f5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"αλλα αν αντι απο αυτα αυτεσ αυτη αυτο αυτοι αυτοσ αυτουσ αυτων αἱ αἳ αἵ αὐτόσ αὐτὸς αὖ γάρ γα γα^ γε για γοῦν γὰρ δ' δέ δή δαί δαίσ δαὶ δαὶς δε δεν δι' διά διὰ δὲ δὴ δ’ εαν ειμαι ειμαστε ειναι εισαι ειστε εκεινα εκεινεσ εκεινη εκεινο εκεινοι εκεινοσ εκεινουσ εκεινων ενω επ επι εἰ εἰμί εἰμὶ εἰς εἰσ εἴ εἴμι εἴτε η θα ισωσ κ καί καίτοι καθ και κατ κατά κατα κατὰ καὶ κι κἀν κἂν μέν μή μήτε μα με μεθ μετ μετά μετα μετὰ μη μην μἐν μὲν μὴ μὴν να ο οι ομωσ οπωσ οσο οτι οἱ οἳ οἷς οὐ οὐδ οὐδέ οὐδείσ οὐδεὶς οὐδὲ οὐδὲν οὐκ οὐχ οὐχὶ οὓς οὔτε οὕτω οὕτως οὕτωσ οὖν οὗ οὗτος οὗτοσ παρ παρά παρα παρὰ περί περὶ ποια ποιεσ ποιο ποιοι ποιοσ ποιουσ ποιων ποτε που ποῦ προ προσ πρόσ πρὸ πρὸς πως πωσ σε στη στην στο στον σόσ σύ σύν σὸς σὺ σὺν τά τήν τί τίς τίσ τα ταῖς τε την τησ τι τινα τις τισ το τοί τοι τοιοῦτος τοιοῦτοσ τον τοτε του τούσ τοὺς τοῖς τοῦ των τό τόν τότε τὰ τὰς τὴν τὸ τὸν τῆς τῆσ τῇ τῶν τῷ ωσ ἀλλ' ἀλλά ἀλλὰ ἀλλ’ ἀπ ἀπό ἀπὸ ἀφ ἂν ἃ ἄλλος ἄλλοσ ἄν ἄρα ἅμα ἐάν ἐγώ ἐγὼ ἐκ ἐμόσ ἐμὸς ἐν ἐξ ἐπί ἐπεὶ ἐπὶ ἐστι ἐφ ἐὰν ἑαυτοῦ ἔτι ἡ ἢ ἣ ἤ ἥ ἧς ἵνα ὁ ὃ ὃν ὃς ὅ ὅδε ὅθεν ὅπερ ὅς ὅσ ὅστις ὅστισ ὅτε ὅτι ὑμόσ ὑπ ὑπέρ ὑπό ὑπὲρ ὑπὸ ὡς ὡσ ὥς ὥστε ὦ ᾧ \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "stopwords.raw('greek').replace('\\n', ' ') # Better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLAZpVtexqy3",
        "outputId": "99ffcff9-3647-499d-9f94-b35109225e57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "stopwords.words('english')[:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqwS6UxPxqy5",
        "outputId": "dd3fa883-686e-40dd-d815-d91d99c68c8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "444"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(stopwords.words(['english', 'greek'])) # There is a total of 444 Greek and English stop words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzMySvBIxqy5"
      },
      "source": [
        "## 3. The classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVleKOitxqy5"
      },
      "source": [
        "We loop through the list of stop words in all languages and check how many stop words our test text contains in each language. The text is then classified to be in the language in which it has the most stop words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG9n9DJ7xqy5",
        "outputId": "e3e5df9e-e7a1-4499-a7c1-435b5e33f7a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'de', 'dieu', \"'\", 'bénit', ';', 'remplissez', 'multipliez', 'l', 'leur', ':', 'assujettissez', 'féconds', 'sur', 'terre', 'poissons', 'les', 'soyez', 'dit', 'mer', ',', 'la', 'et', 'dominez'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'arabic': 0,\n",
              " 'azerbaijani': 1,\n",
              " 'basque': 0,\n",
              " 'bengali': 0,\n",
              " 'catalan': 4,\n",
              " 'chinese': 0,\n",
              " 'danish': 2,\n",
              " 'dutch': 2,\n",
              " 'english': 0,\n",
              " 'finnish': 1,\n",
              " 'french': 8,\n",
              " 'german': 0,\n",
              " 'greek': 0,\n",
              " 'hebrew': 0,\n",
              " 'hinglish': 1,\n",
              " 'hungarian': 1,\n",
              " 'indonesian': 0,\n",
              " 'italian': 2,\n",
              " 'kazakh': 0,\n",
              " 'nepali': 0,\n",
              " 'norwegian': 2,\n",
              " 'portuguese': 1,\n",
              " 'romanian': 2,\n",
              " 'russian': 0,\n",
              " 'slovene': 0,\n",
              " 'spanish': 3,\n",
              " 'swedish': 1,\n",
              " 'tajik': 0,\n",
              " 'turkish': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "language_ratios = {}\n",
        "\n",
        "test_words = [word.lower() for word in test_tokens] # lowercase all tokens\n",
        "test_words_set = set(test_words)\n",
        "print(test_words_set)\n",
        "for language in stopwords.fileids():\n",
        "    stopwords_set = set(stopwords.words(language)) # For some languages eg. Russian, it would be a wise idea to tokenize the stop words by punctuation too.\n",
        "    common_elements = test_words_set.intersection(stopwords_set)\n",
        "    language_ratios[language] = len(common_elements) # language \"score\" by counting\n",
        "    \n",
        "language_ratios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oNhKVfK-xqy6",
        "outputId": "75773087-d814-4a4e-ffb4-6e18c11d24ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'french'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "most_rated_language = max(language_ratios, key=language_ratios.get) # The key parameter to the max() function is a function that computes a key. In our case, we already have a key so we set key to languages_ratios.get which actually returns the key.\n",
        "most_rated_language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlIBQ_-9xqy6",
        "outputId": "1df56caa-8620-4fc1-b893-ab4aebdf9ce5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'de', 'et', 'l', 'la', 'les', 'leur', 'soyez', 'sur'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "test_words_set.intersection(set(stopwords.words(most_rated_language))) # We can see which English stop words were found."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ICP: Perform language detection on a corpus/custom text. \n",
        "\n",
        "1.   Choose your own sentence/paragraph and perform language classification above by \n",
        "loading a longer `.txt` file or a random sentence from a corpus from NLTK.\n",
        "2.   Detect 3 languages from one or more corpora\n",
        "\n",
        "\n",
        "\n",
        "Hint (if you are using NLTK):\n",
        "\n",
        "```python\n",
        "import nltk.corpus\n",
        "from nltk.corpus import genesis\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "_tklDciCBR5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.corpus\n",
        "from nltk.corpus import genesis\n",
        "genesis.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWIC1pNkB4C0",
        "outputId": "aae64190-0f11-4051-ed72-a6c76a587c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['english-kjv.txt',\n",
              " 'english-web.txt',\n",
              " 'finnish.txt',\n",
              " 'french.txt',\n",
              " 'german.txt',\n",
              " 'lolcat.txt',\n",
              " 'portuguese.txt',\n",
              " 'swedish.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XIboGn30CIh9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Language Detection (with Stop Words)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}