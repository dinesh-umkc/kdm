{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinesh-umkc/kdm/blob/main/Gender_Prediction_by_Name_ICP2_a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3vKn1HhWPGa"
      },
      "source": [
        "# Objective: Name Gender Identifier\n",
        "1. Add feature with two letter from name\n",
        "2. Add feature with last letter from name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8y5VrHjWPGg",
        "outputId": "562ccbf5-72ad-4cb4-8bf0-9e275c078b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier 1 Accuraccy: 0.76\n",
            "Classifier 2 Accuraccy: 0.78\n",
            "Classifier 3 Accuraccy: 0.82\n",
            "Most Informative Features\n",
            "                 suffix2 = 'na'           female : male   =     86.9 : 1.0\n",
            "                 suffix2 = 'la'           female : male   =     62.1 : 1.0\n",
            "                 suffix2 = 'ia'           female : male   =     45.2 : 1.0\n",
            "                 suffix3 = 'ard'            male : female =     42.8 : 1.0\n",
            "                 suffix1 = 'a'            female : male   =     39.0 : 1.0\n",
            "                 suffix2 = 'rd'             male : female =     38.2 : 1.0\n",
            "                 suffix1 = 'k'              male : female =     37.5 : 1.0\n",
            "                 suffix2 = 'us'             male : female =     32.8 : 1.0\n",
            "                 suffix2 = 'ra'           female : male   =     31.2 : 1.0\n",
            "                 suffix2 = 'sa'           female : male   =     31.1 : 1.0\n",
            "                 suffix3 = 'tta'          female : male   =     23.5 : 1.0\n",
            "                 suffix2 = 'ta'           female : male   =     22.7 : 1.0\n",
            "                 suffix2 = 'do'             male : female =     22.7 : 1.0\n",
            "                 suffix3 = 'ana'          female : male   =     22.6 : 1.0\n",
            "                 suffix2 = 'ch'             male : female =     20.5 : 1.0\n",
            "\n",
            "CLASSIFIER 1\n",
            "------------ \n",
            "Female precision: 0.78\n",
            "Male precision: 0.72\n",
            "Female recall: 0.87\n",
            "Male recall: 0.57\n",
            "Female F1 score: 0.82\n",
            "Male F1 score: 0.64\n",
            "\n",
            "CLASSIFIER 2\n",
            "------------ \n",
            "Female precision: 0.82\n",
            "Male precision: 0.71\n",
            "Female recall: 0.84\n",
            "Male recall: 0.68\n",
            "Female F1 score: 0.83\n",
            "Male F1 score: 0.69\n",
            "\n",
            "CLASSIFIER 3\n",
            "------------ \n",
            "Female precision: 0.87\n",
            "Male precision: 0.75\n",
            "Female recall: 0.85\n",
            "Male recall: 0.77\n",
            "Female F1 score: 0.86\n",
            "Male F1 score: 0.76\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('female', 'male', 'Rory'),\n",
              " ('male', 'female', 'Julie'),\n",
              " ('male', 'female', 'Verney'),\n",
              " ('female', 'male', 'Marry'),\n",
              " ('male', 'female', 'Sebastien')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Feature extractor\n",
        "def gender_features(word):\n",
        "    return {'last_letter': word[-1]}\n",
        "def gender_features2(name):\n",
        "    features = {}\n",
        "    features[\"first_letter\"] = name[0].lower()\n",
        "    features[\"last_letter\"] = name[-1].lower()\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
        "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
        "    return features\n",
        "def gender_features3(word):\n",
        "    features = {}\n",
        "    features[\"first_letter\"] = word[0].lower()\n",
        "    features[\"suffix1\"] = word[-1].lower()\n",
        "    features[\"suffix2\"] = word[-2:].lower()\n",
        "    features[\"suffix3\"] = word[-3:].lower()\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        features[\"count({})\".format(letter)] = word.lower().count(letter)\n",
        "        features[\"has({})\".format(letter)] = (letter in word.lower())\n",
        "    return features\n",
        "\n",
        "import nltk\n",
        "import random\n",
        "nltk.download('names')\n",
        "from nltk.corpus import names\n",
        "labeled_names = ([(name, 'female') for name in names.words('female.txt')] + [(name, 'male') for name in names.words('male.txt')])\n",
        "random.shuffle(labeled_names) # We shuffle the data so that we can split it by index into training and test data.\n",
        "labeled_names[:5]\n",
        "\n",
        "#Convert labeled names into feature sets v3\n",
        "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
        "featuresets2 = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
        "featuresets3 = [(gender_features3(n), gender) for (n, gender) in labeled_names]\n",
        "featuresets3[:5]\n",
        "\n",
        "TRAIN_SET_SIZE = round(len(featuresets3) * .8)\n",
        "train_set, test_set= featuresets[:TRAIN_SET_SIZE], featuresets[TRAIN_SET_SIZE:] \n",
        "train_set2, test_set2 = featuresets2[:TRAIN_SET_SIZE], featuresets2[TRAIN_SET_SIZE:]\n",
        "train_set3, test_set3 = featuresets3[:TRAIN_SET_SIZE], featuresets3[TRAIN_SET_SIZE:]\n",
        "\n",
        "from nltk import NaiveBayesClassifier\n",
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "classifier2 = NaiveBayesClassifier.train(train_set2)\n",
        "classifier3 = NaiveBayesClassifier.train(train_set3)\n",
        "\n",
        "from nltk.classify import accuracy\n",
        "print('Classifier 1 Accuraccy: '+str(round(accuracy(classifier, test_set), 2)))\n",
        "print('Classifier 2 Accuraccy: '+str(round(accuracy(classifier2, test_set2), 2)))\n",
        "print('Classifier 3 Accuraccy: '+str(round(accuracy(classifier3, test_set3), 2)))\n",
        "\n",
        "classifier3.show_most_informative_features(15)\n",
        "classifier3.classify(gender_features3('Madison'))\n",
        "\n",
        "import collections\n",
        "\n",
        "# Classifier 1\n",
        "refsets = collections.defaultdict(set) # y true\n",
        "testsets = collections.defaultdict(set) # y pred\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set):\n",
        "    refsets[label].add(i)\n",
        "    observed = classifier.classify(feats)\n",
        "    testsets[observed].add(i)\n",
        "    \n",
        "# Classifier 2\n",
        "refsets2 = collections.defaultdict(set)\n",
        "testsets2 = collections.defaultdict(set)\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set2):\n",
        "    refsets2[label].add(i)\n",
        "    observed = classifier2.classify(feats)\n",
        "    testsets2[observed].add(i)\n",
        "\n",
        "# Classifier 3\n",
        "refsets3 = collections.defaultdict(set)\n",
        "testsets3 = collections.defaultdict(set)\n",
        "\n",
        "for i, (feats, label) in enumerate(test_set3):\n",
        "    refsets3[label].add(i)\n",
        "    observed = classifier3.classify(feats)\n",
        "    testsets3[observed].add(i)\n",
        "\n",
        "from nltk.metrics.scores import (precision, recall, f_measure)\n",
        "\n",
        "\n",
        "args = (\n",
        "    round(precision(refsets['female'], testsets['female']), 2),\n",
        "    round(precision(refsets['male'], testsets['male']), 2),\n",
        "    round(recall(refsets['female'], testsets['female']), 2),\n",
        "    round(recall(refsets['male'], testsets['male']), 2),\n",
        "    round(f_measure(refsets['female'], testsets['female']), 2),\n",
        "    round(f_measure(refsets['male'], testsets['male']), 2)\n",
        ")\n",
        "\n",
        "args2 = (\n",
        "    round(precision(refsets2['female'], testsets2['female']), 2),\n",
        "    round(precision(refsets2['male'], testsets2['male']), 2),\n",
        "    round(recall(refsets2['female'], testsets2['female']), 2),\n",
        "    round(recall(refsets2['male'], testsets2['male']), 2),\n",
        "    round(f_measure(refsets2['female'], testsets2['female']), 2),\n",
        "    round(f_measure(refsets2['male'], testsets2['male']), 2)\n",
        ")\n",
        "args3 = (\n",
        "    round(precision(refsets3['female'], testsets3['female']), 2),\n",
        "    round(precision(refsets3['male'], testsets3['male']), 2),\n",
        "    round(recall(refsets3['female'], testsets3['female']), 2),\n",
        "    round(recall(refsets3['male'], testsets3['male']), 2),\n",
        "    round(f_measure(refsets3['female'], testsets3['female']), 2),\n",
        "    round(f_measure(refsets3['male'], testsets3['male']), 2)\n",
        ")\n",
        "print('''\n",
        "CLASSIFIER 1\n",
        "------------ \n",
        "Female precision: {0}\n",
        "Male precision: {1}\n",
        "Female recall: {2}\n",
        "Male recall: {3}\n",
        "Female F1 score: {4}\n",
        "Male F1 score: {5}\n",
        "\n",
        "CLASSIFIER 2\n",
        "------------ \n",
        "Female precision: {6}\n",
        "Male precision: {7}\n",
        "Female recall: {8}\n",
        "Male recall: {9}\n",
        "Female F1 score: {10}\n",
        "Male F1 score: {11}\n",
        "\n",
        "CLASSIFIER 3\n",
        "------------ \n",
        "Female precision: {12}\n",
        "Male precision: {13}\n",
        "Female recall: {14}\n",
        "Male recall: {15}\n",
        "Female F1 score: {16}\n",
        "Male F1 score: {17}\n",
        "'''.format(*args, *args2, *args3))\n",
        "\n",
        "train_names, test_names = labeled_names[:round(len(featuresets) * .8)], labeled_names[round(len(featuresets) * .8):]\n",
        "\n",
        "errors = []\n",
        "for (name, tag) in test_names:\n",
        "    guess = classifier3.classify(gender_features3(name))\n",
        "    if guess != tag:\n",
        "        errors.append((tag, guess, name))\n",
        "\n",
        "errors[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Observation\n",
        "Adding two more features F1 score increased from .83 to .86 form female and from .69 to .76 for male"
      ],
      "metadata": {
        "id": "CI0rORZyjem7"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}